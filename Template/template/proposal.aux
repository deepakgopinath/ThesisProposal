\relax 
\providecommand \oddpage@label [2]{}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Within this framework of causal Bayesian Networks, autonomy's actions can be thought of as appropriately timed \textit  {interventions} at specific parts of model with specific desired outcomes one of which is to alter the bi-directional information flow between the human and machine thereby affecting the fluency, cooperation and transparency of HAI.}}{ii}}
\citation{laplante1992assistive}
\citation{gopinath2016generative}
\citation{fischinger2016hobbit}
\citation{muelling2017autonomy}
\citation{mataric2007socially}
\citation{simpson2008tooth}
\citation{pilarski2012dynamic}
\citation{huang2015using}
\citation{gopinath2017human}
\citation{wasson2003user}
\citation{demeester2008user}
\citation{hoc2001towards}
\citation{hoffman2007cost}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:intro}{{1}{1}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{intelligence that enables}}{1}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{usually}}{1}}
\citation{koller2009probabilistic}
\citation{cover2012elements}
\citation{pearl2009causality}
\citation{ay2008information}
\citation{kiesler2005fostering}
\citation{bengio2009curriculum}
\citation{kiesler2005fostering}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{model of }}{2}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{This model is utilized by the autonomy to reason about the environment (which includes the human) and make decisions that will affect the overall joint task performance. Within this proposed framework of causal Bayesian networks, autonomy's actions can be interpreted as appropriately timed \textit  {interventions} at different nodes of the network. These interventions, among other things, can potentially alter the bidirectional information flow between human and autonomy, thereby affecting the fluency and transparency of HAI.}}{2}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{due to its potential impact on both subjective and objective aspects of task performance. }}{2}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{learning schemes}}{2}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{training/practice}}{2}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{resulting in better experiment designs and}}{2}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{of autonomous control}}{3}}
\citation{abbink2018topology}
\citation{hiatt2017human}
\citation{javdani2015shared}
\citation{hiatt2017human}
\citation{marr1982vision}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background Literature}{4}}
\newlabel{sec:HRI_SA}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Mathematical Models for Shared Control}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Models for Human Behavior}{4}}
\citation{dragan2013policy}
\citation{uno1989formation}
\citation{ziebart2008maximum}
\citation{dvijotham2010inverse}
\citation{mataric2007socially}
\citation{goil2013using}
\citation{broad2018learning}
\citation{gopinath2017human}
\citation{kelley2008understanding}
\citation{taha2011pomdp}
\citation{chen2018planning}
\citation{dragan2012formalizing}
\citation{murphy2002dynamic}
\citation{tahboub2006intelligent}
\citation{gopinath2017human}
\citation{schoner1995dynamics}
\citation{gopinathdynamic}
\citation{gu2015neural}
\citation{green1995reversible}
\citation{argall2009survey}
\citation{bojarski2016end}
\citation{ziebart2008maximum}
\citation{kirk1970optimal}
\citation{watkins1992q}
\citation{kavraki1996analysis}
\citation{kuffner2000rrt}
\citation{dragan2013legibility}
\citation{storms2014blending}
\citation{muller2006off}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Models for Policy Generation}{6}}
\citation{gopinath2017human}
\citation{khatib1986real}
\citation{ratliff2018riemannian}
\citation{mainprice2016warping}
\citation{simpson2008tooth}
\citation{choi2008laser}
\citation{broad2016towards}
\citation{dragan2013policy}
\citation{trautman2015assistive}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Models for Control Allocation}{7}}
\citation{gopinath2017human}
\citation{pilarski2012dynamic}
\citation{herlant2016assistive}
\citation{jainrobot}
\citation{gopinath2017mode}
\citation{guastello1998origins}
\citation{kozlowski2012dynamics}
\citation{rand2013human}
\citation{tomasello2007shared}
\citation{tomasello2007shared}
\citation{bratman1992shared}
\citation{bratman1992shared}
\citation{clark1996using}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Characteristics of Ideal HAI}{8}}
\citation{kiesler2005fostering}
\citation{klien2004ten}
\citation{lyons2014transparency}
\citation{hoffman2007cost}
\citation{thomaz2011turn}
\citation{nikolaidis2012human}
\citation{egli2016call}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Summary}{10}}
\citation{tishby2011information}
\citation{cutsuridis2013cognitive}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Modeling Framework for HAI in Shared Autonomy}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Causal Bayesian Networks for HAI}{11}}
\citation{pearl2009causality}
\citation{schreiber2000measuring}
\citation{ay2008information}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Our model of Human-Autonomy Interaction as a coupled perception-action loop that unfolds in time represented as a Causal Bayesian Network. The nodes represent various relevant variables that interact with each other at discrete time steps. $\textbf  {w}_t$ refers to the world state (includes the robot). $\textbf  {s}^h_t$ and $\textbf  {s}^a_t$ denote the internal state of the human and autonomy respectively. $\textbf  {o}^h_t$ and $\textbf  {o}^a_t$ refer to the noisy observations of the true robot state that are accessible to the human and autonomy respectively. $\textbf  {a}^h_t$ represents the action taken by the human and $\textbf  {u}^h_t$ denotes the human control command as filtered through a control interface such as a joystick. $\textbf  {u}^a_t$ represents the autonomy's control command. The evolution of robot state is governed by the stochastic dynamics of the environment. Note that, this CBN represents one of the many different ways in which autonomy and human interact.}}{12}}
\newlabel{fig:cbn}{{1}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Primer on Information Theory}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Entropy and Mutual Information}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Transfer Entropy}{14}}
\newlabel{eq:te}{{1}{14}}
\citation{silverman1986density}
\citation{kraskov2004estimating}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Estimation from Data}{15}}
\citation{lyons2013being}
\citation{endsley2017here}
\citation{theodorou2017designing}
\citation{schreiber2000measuring}
\@writefile{toc}{\contentsline {section}{\numberline {4}Proposed Contributions}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Information Theoretic Quantification of Transparency}{16}}
\newlabel{study:rq1}{{4.1}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Introduction}{16}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Although transparency has been recognized as a critical component for successful HAI, one of the main goals of this study is to quantify transparency more concretely in information theoretic terms. Such a characterization will help in designing control policies that reason explicitly about subjective aspects of task performance and will likely result in better user satisfaction and acceptance. More specifically, we propose to use the notion of multivariate transfer entropy to characterize the information flow between the nodes in the Bayesian Network shown in Figure\nobreakspace  {}1\hbox {}. Transfer entropy is an information-theoretic metric that aims to capture the \textit  {directed information flow/transfer} from a source random process to a target random process\nobreakspace  {}\cite  {schreiber2000measuring}. Higher transfer entropy implies that knowledge of the source process's past state improves the predictability of the target process's future state. }}{16}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Our hypothesis is that, in a task in which the agents have well-defined goals (could be a shared goal), improvement of transparency (and \textit  {consequently} the predictability) of one of the agent's actions can result in increased predictability of other agents' actions as well. That is, if one agent makes an attempt to be more transparent about its internal state and intentions, the other agent(s) (under rationality assumption) will likely make use of the information that was made available as a result of transparent behavior and act more predictably. That is, higher transparency implies higher predictability of actions and vice versa. }}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Contributions}{16}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{The main contributions of this study will be:}}{16}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Introduction of a theoretical framework based on causal Bayesian Networks for explicit reasoning of information flow between nodes of the network to characterize fluency, coordination and transparency of HAI. }}{16}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{An information theoretic characterization of transparency in human-autonomy interaction utilizing the notion of \textit  {transfer entropy} directly from sensor data.}}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Approach}{16}}
\newlabel{eq:transp}{{2}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Experimental Design}{17}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{These independent factors were chosen so that they directly affect the legibility of motion thereby affecting autonomy-to-human transparency.}}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Simulated 2D point robot environment. Left: The autonomy controlled robot is represented as a white solid circle. The goals are represented in different colors and shapes (green square and red triangle). Right: The human controlled robot is represented as a solid gray circle. The different goals are represented in different colors and shapes (green square and red triangle). For each trial, the autonomy controlled robot will move towards one of the two goals (unknown to the user). The user has to infer what the autonomy's goal and teleoperate the human-controlled robot to the similar goal. }}{18}}
\newlabel{fig:2d_exp}{{2}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Guided Active Learning in Humans}{18}}
\newlabel{study:rq2}{{4.2}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Introduction}{18}}
\citation{gopinath2017human}
\citation{gopinath2017mode}
\citation{mussaivaldi2000motor}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{For example, for novice users familiarity with the device and knowledge about the dynamics of the control interface and the robot increase gradually with training and practice\nobreakspace  {}\cite  {mussaivaldi2000motor}. The initial forward (and inverse) kinematics (or dynamics) model that the user maintains internally at the beginning of training might be drastically different from the true underlying system kinematics (or dynamics). As a result of learning, the internal model will likely become closer to the true model. However, the learning strategies that humans adopt need not always be optimal, for example, users might not explore the state and action space in an efficient and exhaustive manner and therefore can erroneously extrapolate the learned internal model between different regions of the workspace. }}{19}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{In this study, I am interested in exploring \textit  {how autonomy can help the human in skill acquisition, specifically robot teleoperation using low-dimensional control interfaces}. I am inspired by ideas in \textit  {curriculum learning} in which a learner (an animal or an artificial machine learning system) learns about a training distribution or a hypothesis by exploring a set of examples following a systematic curriculum, typically by experiencing `easy' examples first followed by the harder ones. }}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Contributions}{20}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{The main contributions of this study will be}}{20}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Utilization of ergodicity to characterize how users explore the state space during training to reveal the difficulties faced by users while learning how to control the robot.}}{20}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{An algorithm to generate an iterative training curriculum in order to make the training phase more efficient for better experiments and faster skill acquisition.}}{20}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Introducing the role of autonomy as an informative teacher (or a coach) that can help the users with maximal skill acquisition.}}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Approach}{20}}
\newlabel{sssec:learning_approach}{{4.2.3}{20}}
\citation{kiesler2005fostering}
\citation{herlant2016assistive}
\citation{zhang2017human}
\citation{javdani2015shared}
\citation{jainrobot}
\citation{javdani2015shared}
\citation{kim2012autonomy}
\citation{gopinath2017human}
\citation{kiesler2005fostering}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Experiment Design}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Optimizing Task Performance}{21}}
\newlabel{study:rq3}{{4.3}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Introduction}{21}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Typical design of autonomy for shared-control systems aims to improve various objective aspects of joint task performance, such as task completion times\nobreakspace  {}\cite  {herlant2016assistive}, energy consumption\nobreakspace  {}\cite  {zhang2017human} and inference accuracy\nobreakspace  {}\cite  {javdani2015shared}\nobreakspace  {}\cite  {jainrobot}. Optimization-based techniques are used to derive autonomy's policy in which the cost functions that capture desired behavior are pre-specified by the system designer\nobreakspace  {}\cite  {javdani2015shared}. However, in the domain of assistive shared-control, subjective metrics, such as user satisfaction, comfort and trust, are also of paramount importance for successful adoption of these technologies\nobreakspace  {}\cite  {kim2012autonomy}. Determining the exact mathematical structure for the cost function that incorporates these subjective metrics is likely an intractable problem\nobreakspace  {}\cite  {gopinath2017human}.}}{21}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{in addition to objective task-specific metrics}}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Approach}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Contributions}{22}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{The contributions of this study is two-fold:}}{22}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{An integrated pipeline in which autonomy explicitly reasons about the control policy deployed by humans when teleoperating robots in the presence of autonomy, optimizes for transparency in HAI in addition to task-specific objective metrics and arbitrate between human and autonomy commands. }}{22}}
\@writefile{loc}{\contentsline {subsection}{Added: \truncate {.3\textwidth }{Development of data-driven models of how humans teleoperate the robot in the presence of robot autonomy.}}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Experiment Design}{22}}
\bibstyle{plain}
\bibdata{references}
\bibcite{abbink2018topology}{1}
\bibcite{argall2009survey}{2}
\bibcite{ay2008information}{3}
\bibcite{bengio2009curriculum}{4}
\bibcite{bojarski2016end}{5}
\bibcite{bratman1992shared}{6}
\bibcite{broad2016towards}{7}
\bibcite{broad2018learning}{8}
\bibcite{chen2018planning}{9}
\bibcite{choi2008laser}{10}
\bibcite{clark1996using}{11}
\bibcite{cover2012elements}{12}
\bibcite{cutsuridis2013cognitive}{13}
\bibcite{demeester2008user}{14}
\@writefile{toc}{\contentsline {section}{\numberline {5}Timeline}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Plan for Completion of Research}{24}}
\bibcite{dragan2013legibility}{15}
\bibcite{dragan2012formalizing}{16}
\bibcite{dragan2013policy}{17}
\bibcite{dvijotham2010inverse}{18}
\bibcite{egli2016call}{19}
\bibcite{endsley2017here}{20}
\bibcite{fischinger2016hobbit}{21}
\bibcite{goil2013using}{22}
\bibcite{gopinath2017mode}{23}
\bibcite{gopinathdynamic}{24}
\bibcite{gopinath2017human}{25}
\bibcite{gopinath2016generative}{26}
\bibcite{green1995reversible}{27}
\bibcite{gu2015neural}{28}
\bibcite{guastello1998origins}{29}
\bibcite{herlant2016assistive}{30}
\bibcite{hiatt2017human}{31}
\bibcite{hoc2001towards}{32}
\bibcite{hoffman2007cost}{33}
\bibcite{huang2015using}{34}
\bibcite{jainrobot}{35}
\bibcite{javdani2015shared}{36}
\bibcite{kavraki1996analysis}{37}
\bibcite{kelley2008understanding}{38}
\bibcite{khatib1986real}{39}
\bibcite{kiesler2005fostering}{40}
\bibcite{kim2012autonomy}{41}
\bibcite{kirk1970optimal}{42}
\bibcite{klien2004ten}{43}
\bibcite{koller2009probabilistic}{44}
\bibcite{kozlowski2012dynamics}{45}
\bibcite{kraskov2004estimating}{46}
\bibcite{kuffner2000rrt}{47}
\bibcite{laplante1992assistive}{48}
\bibcite{lyons2013being}{49}
\bibcite{lyons2014transparency}{50}
\bibcite{mainprice2016warping}{51}
\bibcite{marr1982vision}{52}
\bibcite{mataric2007socially}{53}
\bibcite{muelling2017autonomy}{54}
\bibcite{muller2006off}{55}
\bibcite{murphy2002dynamic}{56}
\bibcite{mussaivaldi2000motor}{57}
\bibcite{nikolaidis2012human}{58}
\bibcite{pearl2009causality}{59}
\bibcite{pilarski2012dynamic}{60}
\bibcite{rand2013human}{61}
\bibcite{ratliff2018riemannian}{62}
\bibcite{schoner1995dynamics}{63}
\bibcite{schreiber2000measuring}{64}
\bibcite{silverman1986density}{65}
\bibcite{simpson2008tooth}{66}
\bibcite{storms2014blending}{67}
\bibcite{taha2011pomdp}{68}
\bibcite{tahboub2006intelligent}{69}
\bibcite{theodorou2017designing}{70}
\bibcite{thomaz2011turn}{71}
\bibcite{tishby2011information}{72}
\bibcite{tomasello2007shared}{73}
\bibcite{trautman2015assistive}{74}
\bibcite{uno1989formation}{75}
\bibcite{wasson2003user}{76}
\bibcite{watkins1992q}{77}
\bibcite{zhang2017human}{78}
\bibcite{ziebart2008maximum}{79}
